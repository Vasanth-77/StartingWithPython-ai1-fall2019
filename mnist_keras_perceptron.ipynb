{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist-keras-perceptron.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vasanth-77/StartingWithPython-ai1-fall2019/blob/master/mnist_keras_perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rrbVKm5n6E3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# taken from lukas/ml-class\n",
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Dropout\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import Callback\n",
        "import json\n",
        "\n",
        "# from wandb.keras import WandbCallback\n",
        "# import wandb\n",
        "\n",
        "# run = wandb.init()\n",
        "# config = run.config\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bgcIFMpUgYv",
        "colab_type": "text"
      },
      "source": [
        "### Hello World\n",
        "\n",
        "1.One\n",
        "\n",
        "2.Two\n",
        "\n",
        "3.Three\n",
        "\n",
        "ddghdtfghdjhdfhfdggdygdydgydgyygdyydgygde\n",
        "yedgeydgyegdydygdygdyggdygdydyeydg\n",
        "\n",
        "-hello\n",
        "-waorld\n",
        "-gunnu\n",
        "\n",
        "Hello the $\\alpha$ is a greek letter.\n",
        "$$\\alpha + \\beta + \\gamma = \\delta$$\n",
        "\n",
        "---\n",
        "\n",
        "*alpha*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwD2SO3FUdE5",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Gq6S5C7USi2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "04624c98-f9dd-4e05-b444-51be8195fa40"
      },
      "source": [
        "a=(1,2)\n",
        "type(a)\n",
        "\n",
        "\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tuple"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUzDPQa4Rapu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6c94a188-78b0-418f-fbe3-d1d3963b0a4f"
      },
      "source": [
        "class Config:\n",
        "  pass\n",
        "\n",
        "config = Config()\n",
        "config.optimizer = \"adam\"\n",
        "config.epochs = 30\n",
        "config.hidden_nodes = 30\n",
        "\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "img_width = X_train.shape[1]\n",
        "img_height = X_train.shape[2]\n",
        "print(X_train.shape, y_train.shape)\n",
        "#X_train = X_train.astype('float32')\n",
        "#X_train /= 255.\n",
        "#X_test = X_test.astype('float32')\n",
        "#X_test /= 255.\n",
        "\n",
        "# Normalize, change learning rate, play with layer size, batchsize\n",
        "\n",
        "# one hot encode outputs\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "labels = range(10)\n",
        "\n",
        "num_classes = y_train.shape[1]\n",
        "\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28) (60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5j9gef_EyyKi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f85ac3ce-8020-410b-ff29-b519283da5ff"
      },
      "source": [
        "X_train[0]"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
              "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
              "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
              "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
              "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
              "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
              "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
              "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
              "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
              "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
              "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
              "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
              "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rxc_XPdURrbi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "16b1e90d-5a6d-4609-cc17-13cf00165616"
      },
      "source": [
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(img_width, img_height)))\n",
        "model.add(Dense(config.hidden_nodes, activation='relu'))\n",
        "model.add(Dense(config.hidden_nodes, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer=config.optimizer,\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_2 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 30)                23550     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 30)                930       \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                310       \n",
            "=================================================================\n",
            "Total params: 24,790\n",
            "Trainable params: 24,790\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_12mmlySXF7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "085e73f6-98ce-405f-ee4c-76497946b079"
      },
      "source": [
        "# Fit the model\n",
        "history=model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
        "          epochs=config.epochs)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 8.1328 - acc: 0.4885 - val_loss: 7.0917 - val_acc: 0.5528\n",
            "Epoch 2/30\n",
            "60000/60000 [==============================] - 10s 166us/step - loss: 6.4272 - acc: 0.5960 - val_loss: 5.7420 - val_acc: 0.6401\n",
            "Epoch 3/30\n",
            "60000/60000 [==============================] - 10s 167us/step - loss: 5.3520 - acc: 0.6641 - val_loss: 4.1643 - val_acc: 0.7386\n",
            "Epoch 4/30\n",
            "60000/60000 [==============================] - 10s 166us/step - loss: 4.0141 - acc: 0.7471 - val_loss: 3.1029 - val_acc: 0.8023\n",
            "Epoch 5/30\n",
            "60000/60000 [==============================] - 10s 174us/step - loss: 2.8608 - acc: 0.8195 - val_loss: 2.6701 - val_acc: 0.8314\n",
            "Epoch 6/30\n",
            "60000/60000 [==============================] - 10s 167us/step - loss: 2.6653 - acc: 0.8320 - val_loss: 2.5503 - val_acc: 0.8397\n",
            "Epoch 7/30\n",
            "60000/60000 [==============================] - 10s 166us/step - loss: 2.6483 - acc: 0.8335 - val_loss: 2.6915 - val_acc: 0.8307\n",
            "Epoch 8/30\n",
            "60000/60000 [==============================] - 10s 167us/step - loss: 2.5864 - acc: 0.8378 - val_loss: 2.5654 - val_acc: 0.8398\n",
            "Epoch 9/30\n",
            "60000/60000 [==============================] - 10s 166us/step - loss: 2.5873 - acc: 0.8379 - val_loss: 2.5229 - val_acc: 0.8421\n",
            "Epoch 10/30\n",
            "60000/60000 [==============================] - 10s 165us/step - loss: 2.5832 - acc: 0.8381 - val_loss: 2.5886 - val_acc: 0.8383\n",
            "Epoch 11/30\n",
            "60000/60000 [==============================] - 10s 164us/step - loss: 2.5680 - acc: 0.8393 - val_loss: 2.4134 - val_acc: 0.8494\n",
            "Epoch 12/30\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 2.5381 - acc: 0.8412 - val_loss: 2.6597 - val_acc: 0.8334\n",
            "Epoch 13/30\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 2.5653 - acc: 0.8398 - val_loss: 2.5984 - val_acc: 0.8369\n",
            "Epoch 14/30\n",
            "60000/60000 [==============================] - 10s 166us/step - loss: 2.5066 - acc: 0.8433 - val_loss: 2.5959 - val_acc: 0.8383\n",
            "Epoch 15/30\n",
            "60000/60000 [==============================] - 10s 168us/step - loss: 2.5811 - acc: 0.8387 - val_loss: 2.6036 - val_acc: 0.8375\n",
            "Epoch 16/30\n",
            "60000/60000 [==============================] - 10s 167us/step - loss: 2.4777 - acc: 0.8453 - val_loss: 2.6116 - val_acc: 0.8372\n",
            "Epoch 17/30\n",
            "60000/60000 [==============================] - 10s 166us/step - loss: 2.5154 - acc: 0.8432 - val_loss: 2.7336 - val_acc: 0.8294\n",
            "Epoch 18/30\n",
            "60000/60000 [==============================] - 10s 166us/step - loss: 2.5023 - acc: 0.8441 - val_loss: 2.4727 - val_acc: 0.8454\n",
            "Epoch 19/30\n",
            "60000/60000 [==============================] - 10s 163us/step - loss: 2.4319 - acc: 0.8483 - val_loss: 2.4570 - val_acc: 0.8465\n",
            "Epoch 20/30\n",
            "60000/60000 [==============================] - 10s 166us/step - loss: 2.4402 - acc: 0.8480 - val_loss: 2.4770 - val_acc: 0.8457\n",
            "Epoch 21/30\n",
            "60000/60000 [==============================] - 10s 168us/step - loss: 2.5434 - acc: 0.8415 - val_loss: 2.4528 - val_acc: 0.8471\n",
            "Epoch 22/30\n",
            "60000/60000 [==============================] - 10s 167us/step - loss: 2.4265 - acc: 0.8489 - val_loss: 2.6596 - val_acc: 0.8340\n",
            "Epoch 23/30\n",
            "60000/60000 [==============================] - 10s 167us/step - loss: 2.4391 - acc: 0.8481 - val_loss: 2.4123 - val_acc: 0.8495\n",
            "Epoch 24/30\n",
            "60000/60000 [==============================] - 10s 164us/step - loss: 2.4168 - acc: 0.8494 - val_loss: 2.4150 - val_acc: 0.8498\n",
            "Epoch 25/30\n",
            "60000/60000 [==============================] - 10s 165us/step - loss: 2.4947 - acc: 0.8446 - val_loss: 2.4588 - val_acc: 0.8469\n",
            "Epoch 26/30\n",
            "60000/60000 [==============================] - 10s 167us/step - loss: 2.3989 - acc: 0.8507 - val_loss: 2.4441 - val_acc: 0.8473\n",
            "Epoch 27/30\n",
            "60000/60000 [==============================] - 10s 166us/step - loss: 2.4264 - acc: 0.8489 - val_loss: 2.3123 - val_acc: 0.8558\n",
            "Epoch 28/30\n",
            "60000/60000 [==============================] - 10s 165us/step - loss: 2.4744 - acc: 0.8459 - val_loss: 2.4732 - val_acc: 0.8462\n",
            "Epoch 29/30\n",
            "60000/60000 [==============================] - 10s 166us/step - loss: 2.3713 - acc: 0.8524 - val_loss: 2.4858 - val_acc: 0.8452\n",
            "Epoch 30/30\n",
            "60000/60000 [==============================] - 10s 165us/step - loss: 2.3868 - acc: 0.8516 - val_loss: 2.6482 - val_acc: 0.8350\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tzR5CEKRixt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d0ef458e-633e-4faf-e730-e4ff11d1fa0a"
      },
      "source": [
        "y_train.shape\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lD_yP87RlYu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4408a58d-733f-4e8a-9a99-312123c9ee13"
      },
      "source": [
        "X_test.shape\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxQgU1riyIM_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "61ca9d7a-32bb-41bf-b24a-2bdd1846d23b"
      },
      "source": [
        "dir()\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Callback',\n",
              " 'Config',\n",
              " 'Dense',\n",
              " 'Dropout',\n",
              " 'Flatten',\n",
              " 'In',\n",
              " 'Out',\n",
              " 'Sequential',\n",
              " 'X_test',\n",
              " 'X_train',\n",
              " '_',\n",
              " '_10',\n",
              " '_14',\n",
              " '_23',\n",
              " '_25',\n",
              " '_26',\n",
              " '_27',\n",
              " '_30',\n",
              " '_36',\n",
              " '_38',\n",
              " '_41',\n",
              " '_42',\n",
              " '_43',\n",
              " '_44',\n",
              " '_45',\n",
              " '_46',\n",
              " '_51',\n",
              " '_53',\n",
              " '_56',\n",
              " '_57',\n",
              " '__',\n",
              " '___',\n",
              " '__builtin__',\n",
              " '__builtins__',\n",
              " '__doc__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__spec__',\n",
              " '_dh',\n",
              " '_i',\n",
              " '_i1',\n",
              " '_i10',\n",
              " '_i11',\n",
              " '_i12',\n",
              " '_i13',\n",
              " '_i14',\n",
              " '_i15',\n",
              " '_i16',\n",
              " '_i17',\n",
              " '_i18',\n",
              " '_i19',\n",
              " '_i2',\n",
              " '_i20',\n",
              " '_i21',\n",
              " '_i22',\n",
              " '_i23',\n",
              " '_i24',\n",
              " '_i25',\n",
              " '_i26',\n",
              " '_i27',\n",
              " '_i28',\n",
              " '_i29',\n",
              " '_i3',\n",
              " '_i30',\n",
              " '_i31',\n",
              " '_i32',\n",
              " '_i33',\n",
              " '_i34',\n",
              " '_i35',\n",
              " '_i36',\n",
              " '_i37',\n",
              " '_i38',\n",
              " '_i39',\n",
              " '_i4',\n",
              " '_i40',\n",
              " '_i41',\n",
              " '_i42',\n",
              " '_i43',\n",
              " '_i44',\n",
              " '_i45',\n",
              " '_i46',\n",
              " '_i47',\n",
              " '_i48',\n",
              " '_i49',\n",
              " '_i5',\n",
              " '_i50',\n",
              " '_i51',\n",
              " '_i52',\n",
              " '_i53',\n",
              " '_i54',\n",
              " '_i55',\n",
              " '_i56',\n",
              " '_i57',\n",
              " '_i58',\n",
              " '_i6',\n",
              " '_i7',\n",
              " '_i8',\n",
              " '_i9',\n",
              " '_ih',\n",
              " '_ii',\n",
              " '_iii',\n",
              " '_oh',\n",
              " '_sh',\n",
              " 'a',\n",
              " 'config',\n",
              " 'exit',\n",
              " 'get_ipython',\n",
              " 'history',\n",
              " 'img_height',\n",
              " 'img_width',\n",
              " 'json',\n",
              " 'labels',\n",
              " 'mnist',\n",
              " 'model',\n",
              " 'np',\n",
              " 'np_utils',\n",
              " 'num_classes',\n",
              " 'plt',\n",
              " 'quit',\n",
              " 'y_test',\n",
              " 'y_train']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSk7qH2QyPKt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "64a0dc5e-332b-4128-a9da-adf189a943de"
      },
      "source": [
        "_23"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
              "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
              "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
              "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
              "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
              "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
              "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
              "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
              "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
              "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
              "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
              "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
              "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xN8-K-ZDydFx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "333a5145-890a-45fc-b4b0-f9b176acd7a6"
      },
      "source": [
        "history.history"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'acc': [0.4884833333333333,\n",
              "  0.5960333333333333,\n",
              "  0.66405,\n",
              "  0.7470833333333333,\n",
              "  0.8194666666666667,\n",
              "  0.8319833333333333,\n",
              "  0.8335333333333333,\n",
              "  0.8378,\n",
              "  0.8378666666666666,\n",
              "  0.8381333333333333,\n",
              "  0.8393166666666667,\n",
              "  0.84125,\n",
              "  0.8397833333333333,\n",
              "  0.8433,\n",
              "  0.8387166666666667,\n",
              "  0.8453166666666667,\n",
              "  0.8431666666666666,\n",
              "  0.8440666666666666,\n",
              "  0.84835,\n",
              "  0.8479833333333333,\n",
              "  0.8415,\n",
              "  0.8488833333333333,\n",
              "  0.84805,\n",
              "  0.8493833333333334,\n",
              "  0.8445666666666667,\n",
              "  0.8506833333333333,\n",
              "  0.8489333333333333,\n",
              "  0.8459,\n",
              "  0.8523833333333334,\n",
              "  0.8515833333333334],\n",
              " 'loss': [8.132766969426473,\n",
              "  6.42717420832316,\n",
              "  5.351972170130412,\n",
              "  4.014060228204394,\n",
              "  2.860794380419453,\n",
              "  2.6652670904527107,\n",
              "  2.648251887418229,\n",
              "  2.586417079138756,\n",
              "  2.587308005303765,\n",
              "  2.5832117152076526,\n",
              "  2.568024083884557,\n",
              "  2.538148473914464,\n",
              "  2.5652688601811726,\n",
              "  2.506560104115804,\n",
              "  2.5811413828382888,\n",
              "  2.4777175579615403,\n",
              "  2.5154388530224563,\n",
              "  2.502308115196228,\n",
              "  2.431882816815063,\n",
              "  2.44017994706134,\n",
              "  2.5433703382809956,\n",
              "  2.4264606395532686,\n",
              "  2.4391250737508137,\n",
              "  2.4167631550073625,\n",
              "  2.4947198568662006,\n",
              "  2.398908651701609,\n",
              "  2.4263896825750884,\n",
              "  2.4744108962217966,\n",
              "  2.3713064485867044,\n",
              "  2.3867711486180623],\n",
              " 'val_acc': [0.5528,\n",
              "  0.6401,\n",
              "  0.7386,\n",
              "  0.8023,\n",
              "  0.8314,\n",
              "  0.8397,\n",
              "  0.8307,\n",
              "  0.8398,\n",
              "  0.8421,\n",
              "  0.8383,\n",
              "  0.8494,\n",
              "  0.8334,\n",
              "  0.8369,\n",
              "  0.8383,\n",
              "  0.8375,\n",
              "  0.8372,\n",
              "  0.8294,\n",
              "  0.8454,\n",
              "  0.8465,\n",
              "  0.8457,\n",
              "  0.8471,\n",
              "  0.834,\n",
              "  0.8495,\n",
              "  0.8498,\n",
              "  0.8469,\n",
              "  0.8473,\n",
              "  0.8558,\n",
              "  0.8462,\n",
              "  0.8452,\n",
              "  0.835],\n",
              " 'val_loss': [7.091745306396485,\n",
              "  5.741956990814209,\n",
              "  4.1643281229019165,\n",
              "  3.1029263540267946,\n",
              "  2.6701126668930053,\n",
              "  2.550294747270085,\n",
              "  2.6915292599399576,\n",
              "  2.56544539294932,\n",
              "  2.5229250568389894,\n",
              "  2.588604668235779,\n",
              "  2.413423561668396,\n",
              "  2.659685402870178,\n",
              "  2.5984360567092897,\n",
              "  2.595865252494812,\n",
              "  2.6035636800765993,\n",
              "  2.611571646308899,\n",
              "  2.7336396614670755,\n",
              "  2.4726966705322266,\n",
              "  2.457008699417114,\n",
              "  2.47704566488266,\n",
              "  2.4527720486164095,\n",
              "  2.659609417915344,\n",
              "  2.4122912071228026,\n",
              "  2.4149915552139283,\n",
              "  2.4587795413970945,\n",
              "  2.4440799823760986,\n",
              "  2.312275986289978,\n",
              "  2.473151121711731,\n",
              "  2.4857977586746216,\n",
              "  2.648197521209717]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGhd-p8u5PJj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "80f48adf-d849-48df-8087-eaed1fb87074"
      },
      "source": [
        "history.epoch"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 18,\n",
              " 19,\n",
              " 20,\n",
              " 21,\n",
              " 22,\n",
              " 23,\n",
              " 24,\n",
              " 25,\n",
              " 26,\n",
              " 27,\n",
              " 28,\n",
              " 29]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goRU0c5q5WGZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkaaQIiM5sM9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "eb33dde6-b412-41b3-9588-7ba1f7a8ec7c"
      },
      "source": [
        "plt.plot(history.epoch, history.history['acc'])"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f69e0b3cba8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XlwnPd93/H3F4uLuAECvAleIkXq\npgQxtiXbdBxJrJ1YTpN6pDRTqdNEmSZyruaQOq6sKvXU00maTGdUJ3LK2M00oRU7tSmLrazGpizK\nlk3wECkeICGIB0iAWFzEfezut3/sQ2oFkcQCWGCvz2tmZ/f57fMsvw9X/Oyj3/N7fo+5OyIikh8K\n0l2AiIgsHIW+iEgeUeiLiOQRhb6ISB5R6IuI5BGFvohIHlHoi4jkEYW+iEgeUeiLiOSRwnQXMFV9\nfb2vXbs23WWIiGSVAwcOdLt7w3TrZVzor127lubm5nSXISKSVczsbDLrqXtHRCSPKPRFRPKIQl9E\nJI8o9EVE8ohCX0Qkjyj0RUTySFKhb2Y7zKzFzFrN7KlrvN9oZj8ws0NmdsTMPhW0rzWzUTM7HDz+\nMtU7ICIiyZt2nL6ZhYDngQeAdmC/me129+MJq30BeNHdv2JmtwB7gLXBe++4+12pLVtEJLO5O0cv\nXOb1092YQVlRiEXFIRYVF7KoKERZcbB85XVRiPKSQspL5vfyqWQ+fRvQ6u5tAGa2C3gYSAx9B6qC\n19XAxVQWKSIyG+d6Rvje8U66BsdZXF5MfUUJ9ZUl1FcU01BRQl15MYWh1PVyuzvHLg7w3SMdvHz0\nIud7R2e0/Z2rqvnOk/enrJ5rSSb0VwLnE5bbgZ+Zss6zwPfM7PNAOfBzCe+tM7NDwADwBXd/ffbl\nisgVXQNjHLs4QCTmFIaMooKC+HPIKAxeX3kuKiigvrKYsuLUHEX2DI3z7cMXaQsPBUeshZQVv3fE\nWhYsLwraSotCDI1HuDwySf/oRPA8Sf/IJJdH44/+kQn6RyepLCnkZ9Yv5kPr62haW0dVaVHSdbk7\nJzoGeeVYJ68c6+Rk5yAAJYUFjEdiH1jfDOrKrvwYxH8I1taXs6GhgpuWVLCuvpzSotC0f+axiwPs\nOdrBy0c7ONszQmGB8ZGb6vn8JzbywC1LWVQcYnQiyshklNGJ4DEZZWQikvA6Sk1Z8vs6W6n6/4hH\nga+5+5+Z2YeBvzWz24AOoNHde8zsHuDbZnaruw8kbmxmTwBPADQ2NqaoJJHcMRGJcbxjgEPn+jh4\nrp+DZ/u40D+zo8jiwgK2b2rg03cs55NbllIxw26ESDTGa6fCvNh8nn860UUk5tSWFTE2GWN0Mjqj\nz7qisrSQ6kVF1JQVUbOomOXViwgPjfO1N87wwg/bKDC4dUU1H1pfx4fWL+bedR/8EYjGnIPn+njl\n7U6+d/wS53pHMIN719TxhU9v4aFbl7GqdhHDE1G6B8fpHoo/woPjhIcm4suD44SHxtl/po/vvHUR\n9/hnm8Gq2kXxH4GGCjYsqWBDQwUbGsq5NDDOy0cv8vKRDs70jBAqMD6yYTG/uX0DD96yjNry4vfV\nWVoUonZWf0upZX5l7663QjzEn3X3h4LlpwHc/T8nrHMM2OHu54PlNuBD7t415bP2An/g7tedXKep\nqck1945kg1OXBvnuWxdp7x9leXUpy6oXsaK6lOXVi1heXUpNWRFmNqvPvjQwxsGzfRw6Hw/4oxcu\nXz1SXV5dyt2NtWxtrOGOVTWUFhUwGXUi0RiRmMcf0Vi8LRYjEnUmo7GrR6Ndg+OUFBbwiZuX8Ok7\nlvOzm5fcsB/5nfAQ/9DczrcOthMOukn++d0r+RdNq9m0tBKAWMwZi0QZHo8GR7QRRoIj2pGJKGOT\nUSpKC6lZVERNWTHVi4qoKi28btfK2GSUg+f6eLOtlzfbejh8rp+JaOx9PwK3rKjip+/28erxS3QP\njVMcKuC+mxbz0K3L+LlbllJfUTKrv/vRiSjvdg/zTniId8JDtHYN8U54mLbw0Af+b6HA4CMb6vn0\nHct56NZl1E0J+oVkZgfcvWna9ZII/ULgFPBJ4AKwH/gVdz+WsM7/Ab7h7l8zsy3APxHvFqoHet09\nambrgdeB292993p/nkJfUsnd6bg8xsnOAU50DBKJOvesiQfmbE6Yvds9zHffushLRy5y6tIQBQZL\nKksJD40Tjb3/31JpUcHVH4Bl1aUsrSolGnOGx+OBePV5IsLIePActF8Jl+JQAbetrOLuxlruDupe\nXr1o1n8fsZjTfLaPl49cZM/bnYQHxyktKuBnNy/h07ev4BObGygrLmRoPMLLRy7yYnM7B872ESow\nPnHzEj7XtIpPbF5CUQr7wZMxNhnl0Ll+3mzr4c22Hg4FPwLlxSG2b17CjluXsf3mBipn0BU0U7GY\nc6F/9OoPQXlJIQ/espTFs/xxSbWUhX7wYZ8C/gIIATvd/Utm9hzQ7O67gxE7XwUqiJ/U/SN3/56Z\n/RLwHDAJxIAvuvtLN/qzFPr5KRKN0TM8waWBMboGxrk0OMb4ZIza8viRYV1ZMbVlxdSWF1FRUnjN\nI+ixySinLg1yoiMe8Cc6BjjZOcjl0cmr65iBO4QKjNtWVNG0to5719Zx79ra6/7jPd87wstHO/ju\nkYu8fSHeM3nv2lp+4c4V7LhtGUsq42EeHhyn4/IoHZfH4o/+UToG4s+dl8foGhynKFRAecl7fd5l\nxfERG2XFIcqLCykriT8vrSpla2MNt6yooqTwxn3KsxWNOc1nenn5aAd7jnbSPTTOoqIQd6+p4eDZ\nfkYno2xoKOdzTav5xbtXsqSydF7qmI2xySjvhIfY0FAxbZ97vkhp6C8khX72c3fGJmMMjk0yMDbJ\n5dFI8DrC5dHJeF/q4BiXBsbpCp57hsaJJfmfYlHIqCkrprYs/oNQWVLImZ5h3u0evvoZZcUhbl5W\nyeZlVdyyvJIty6vYtCzeFXHwbB/NZ/r46ZleDp/vZyI4ql7fUM62tfGTh1uWV/KTtl5eOnKRQ+f6\nAbhzdQ2/cMdyPnX7clbUzP5oOxNFY85P3+3l5aMX+fE7PWxbV8cv37OauxtrZt1FJQtLoS/vMzIR\n4Uj7ZQ6d66e9bwSH4GSV487VE1d+ZTl4P+ZONPbeIxJzYh5/jsZiV9vHIzEGRicZHIswMDbJZPT6\n/12ZweLyEpZWlbCksoSlVaUsqSq9+jreXkpJYQF9IxP0jcRHdvQOT9A/MknvyMTV5b6RSQZGJ1ld\nV8aW5VVsWRYP+Ma6MgoKpg+r8UiUo+2X2X+mj/1nemk+08vAWOTq+1uWV/ELdy7n529fQePisjl9\nByLzSaGfx9ydsz0jHDzXx6Fz/Rw818fJzsGrfc515cXE89AwAyMexEFLQptRUACFBQUUWPBcYBQW\n2NXnkBmhAqO4sICq4ORc1aIiKksLqSotet/r6kXx59ry4gXvE05WLOac6hrk2IUB7lxdw01LKtJd\nkkhSkg39jLtzliRvIhKjb2SCnqEJwkPjHG3v59C5fg6d76d3eAKA8uIQdzXW8JvbN7C1sYa7Vtem\ndYRBpisoMDYvq2LzsqrpVxbJQgr9DHb60iDfP9lF7/AEPcMT9F15Hpmgd2iCwfHIB7bZ0FDOJzcv\nYWtjLXevqWHjkkpCSXRziEh+UOhnoPFIlOe/38p/3/sOkZhTXFjA4vL46JXFFcU01pVRV1589bE4\neN68rIrqBbiiT0Syl0I/wxw428cff+sIrV1D/OLWlTz9qc00VJRoBIWIpIRCP0MMj0f40++18LUf\nnWF5VSl/86/v5RM3L0l3WSKSYxT6GeD102Ge/sejtPeN8q8+vIY/2rF5xvOiiIgkQ8mSRpdHJvlP\nLx/nHw60s76+nBd/48NsW1eX7rJEJIcp9NPk/77dwX/4zjF6hyf4ze0b+O1PbtTl5CIy7xT6Cywa\nc373G4d56a2L3Lqiir95/F5uW1md7rJEJE8o9BfYoXN9vPTWRX7jY+v5g4duztgrU0UkNylxFti+\n1vj9Mv/t9g0KfBFZcEqdBfZGaze3r6ympkxTIYjIwlPoL6Ch8QiHzvVz/0316S5FRPKUQn8B/aSt\nh0jMFfoikjYK/QW0r7WbksIC7l6TCbdHFpF8pNBfQPtOd7NtXZ3G44tI2iQV+ma2w8xazKzVzJ66\nxvuNZvYDMztkZkeCe+peee/pYLsWM3solcVnk0sDY5zuGlLXjoik1bTj9M0sBDwPPAC0A/vNbLe7\nH09Y7QvAi+7+leAm6XuAtcHrR4BbgRXA/zOzTe4eTfWOZLo3WrsBuE+hLyJplMyR/jag1d3b3H0C\n2AU8PGUdB67caqgauBi8fhjY5e7j7v4u0Bp8Xt7Zd7qbuvJiblmuOzKJSPokE/orgfMJy+1BW6Jn\ngV81s3biR/mfn8G2Oc/d2dfazUc2LE7qZt0iIvMlVSdyHwW+5u6rgE8Bf2tmSX+2mT1hZs1m1hwO\nh1NUUuZo7Rqia3Bc/fkiknbJBPMFYHXC8qqgLdG/AV4EcPcfA6VAfZLb4u4vuHuTuzc1NDQkX32W\neP10vD///o0KfRFJr2RCfz+w0czWmVkx8ROzu6escw74JICZbSEe+uFgvUfMrMTM1gEbgZ+mqvhs\n8UZrN2sXl7GqtizdpYhInpt29I67R8zsSeAVIATsdPdjZvYc0Ozuu4F/B3zVzH6P+Endx93dgWNm\n9iJwHIgAv5VvI3cmozHebOvhs1vz7lSGiGSgpKZWdvc9xE/QJrY9k/D6OHDfdbb9EvClOdSY1Q6f\n72d4IspH1bUjIhlAV+TOs32n41Mpf3i9Ql9E0k+hP8/eaO3mjpXVVJcVpbsUERGF/nwaHJvk0Pl+\njdoRkYyh0J9HP2nrJRpzTb0gIhlDoT+P9rV2U1pUwD2aSllEMoRCfx7ta+1m27rFlBRqKmURyQwK\n/XnSeXmM1q4h7r9pcbpLERG5SqE/TzSVsohkIoX+PNnX2s3i8mK2LNNUyiKSORT68+DqVMo31Wsq\nZRHJKAr9eXDq0hDhwXH154tIxlHoz4N9rVemUs69aaJFJLsp9OfBG63drKsvZ2XNonSXIiLyPgr9\nFJuIxKdSvk9dOyKSgRT6KXb4fD8jE1Huv0ldOyKSeRT6KbavtZsCgw+v15G+iGQehX6K7Tsd5vZV\nNZpKWUQykkI/hQbGJnmr/TIf1VW4IpKhkgp9M9thZi1m1mpmT13j/T83s8PB45SZ9Se8F014b+oN\n1XOKplIWkUw37T1yzSwEPA88ALQD+81sd3BfXADc/fcS1v88sDXhI0bd/a7UlZy59p0Os6goxN1r\natJdiojINSVzpL8NaHX3NnefAHYBD99g/UeBv09FcdkmPpVynaZSFpGMlUzorwTOJyy3B20fYGZr\ngHXA9xOaS82s2czeNLPPzrrSDNdxeZR3wsPcr64dEclg03bvzNAjwDfdPZrQtsbdL5jZeuD7ZnbU\n3d9J3MjMngCeAGhsbExxSQtj32lNpSwimS+ZI/0LwOqE5VVB27U8wpSuHXe/EDy3AXt5f3//lXVe\ncPcmd29qaMjOi5p+/E4Pi8uL2bysMt2liIhcVzKhvx/YaGbrzKyYeLB/YBSOmW0GaoEfJ7TVmllJ\n8LoeuA84PnXbXNB8to+mtbWaSllEMtq0oe/uEeBJ4BXgBPCiux8zs+fM7DMJqz4C7HJ3T2jbAjSb\n2VvAD4AvJ476yRWXBsY41zvCvWvr0l2KiMgNJdWn7+57gD1T2p6ZsvzsNbb7EXD7HOrLCs1n+gBo\nUuiLSIbTFbkp0Hy2l9KiAm5doVsjikhmU+inQPOZPu5aXUNRSH+dIpLZlFJzNDwe4XjHAE1r1LUj\nIplPoT9Hh8/3E405TWtr012KiMi0FPpz1HymDzO4e41CX0Qyn0J/jprP9nLz0kqqSjV/vohkPoX+\nHESiMQ6e7dP4fBHJGgr9OTjZOcjwRFT9+SKSNRT6c9B8phfQRVkikj0U+nPQfLaP5dWlrKxZlO5S\nRESSotCfJXen+UyfjvJFJKso9GfpQv8onQNjNGmopohkEYX+LL03yZpCX0Syh0J/lprP9lJRUsjm\nZZpkTUSyh0J/lprP9LG1sYaQbpoiIllEoT8Ll0cnabk0qIuyRCTrKPRn4eC5PtzRSVwRyToK/Vlo\nPtNLqMC4q7Em3aWIiMxIUqFvZjvMrMXMWs3sqWu8/+dmdjh4nDKz/oT3HjOz08HjsVQWny7NZ/q4\ndUUVZcVJ3W1SRCRjTJtaZhYCngceANqB/Wa2O/EG5+7+ewnrfx7YGryuA74INAEOHAi27UvpXiyg\niUiMw+f7+Zc/sybdpYiIzFgyR/rbgFZ3b3P3CWAX8PAN1n8U+Pvg9UPAq+7eGwT9q8COuRScbscu\nXmY8EtP4fBHJSsmE/krgfMJye9D2AWa2BlgHfH+m22aLqxdl6SSuiGShVJ/IfQT4prtHZ7KRmT1h\nZs1m1hwOh1NcUmo1n+1lzeIyllSVprsUEZEZSyb0LwCrE5ZXBW3X8gjvde0kva27v+DuTe7e1NDQ\nkERJ6XFlkrV7dJQvIlkqmdDfD2w0s3VmVkw82HdPXcnMNgO1wI8Tml8BHjSzWjOrBR4M2rLSu93D\n9AxP6KIsEcla047ecfeImT1JPKxDwE53P2ZmzwHN7n7lB+ARYJe7e8K2vWb2J8R/OACec/fe1O7C\nwmk+q/58EcluSQ00d/c9wJ4pbc9MWX72OtvuBHbOsr6M0nyml5qyIjY0VKS7FBGRWdEVuTPQfLaP\nexprKdAkayKSpRT6SeoZGqctPKw7ZYlIVlPoJ+lA0J9/ry7KEpEsptBPUvPZPopDBdy2sjrdpYiI\nzJpCP0nNZ3q5Y1U1pUWhdJciIjJrCv0kjE1GOXrhMveoa0dEspxCPwlvne9nMurcu0YncUUkuyn0\nk3DloixNvyAi2U6hn4TmM73ctKSC2vLidJciIjInCv1pxGLOgbN9mnpBRHKCQn8ap7uGGBiL6KIs\nEckJCv1pNJ+Nzw+ni7JEJBco9KfRfKaP+ooSGuvK0l2KiMicKfSnsf9ML/eurcVMk6yJSPZT6N/A\nxf5R2vtGNVRTRHKGQv8GXjsVv1/vxzZl7i0cRURmQqF/A3tbulhRXcrGJbppiojkBoX+dUxGY7zR\n2sPHb25Qf76I5AyF/nUcONvH0HiEj29aku5SRERSJqnQN7MdZtZiZq1m9tR11vmcmR03s2Nm9ncJ\n7VEzOxw8dl9r20y0tyVMYYFx302L012KiEjKTHtjdDMLAc8DDwDtwH4z2+3uxxPW2Qg8Ddzn7n1m\nlnh4POrud6W47nn32qkw96yppbK0KN2liIikTDJH+tuAVndvc/cJYBfw8JR1fh143t37ANy9K7Vl\nLqxLA2Oc6Bhg+83q2hGR3JJM6K8EzicstwdtiTYBm8zsDTN708x2JLxXambNQftnr/UHmNkTwTrN\n4XB4RjswH15ridew/WYN1RSR3DJt984MPmcjsB1YBfzQzG53935gjbtfMLP1wPfN7Ki7v5O4sbu/\nALwA0NTU5Cmqadb2nupiaVUJm5dVprsUEZGUSuZI/wKwOmF5VdCWqB3Y7e6T7v4ucIr4jwDufiF4\nbgP2AlvnWPO8ikRjvH66m49v0lBNEck9yYT+fmCjma0zs2LgEWDqKJxvEz/Kx8zqiXf3tJlZrZmV\nJLTfBxwngx0638/gWET9+SKSk6bt3nH3iJk9CbwChICd7n7MzJ4Dmt19d/Deg2Z2HIgCf+juPWb2\nEeCvzCxG/Afmy4mjfjLR3pYuQgXGfTfVp7sUEZGUS6pP3933AHumtD2T8NqB3w8eiev8CLh97mUu\nnL0tYe5prKV6kYZqikju0RW5CboGxzh2cYCPa9SOiOQohX6CH57qBuDjmlVTRHKUQj/B3pYuGipL\nuHVFVbpLERGZFwr9gIZqikg+UOgH3mq/zOXRSXXtiEhOU+gHXmvposDgoxs1VFNEcpdCP7D3VJit\njbXUlBWnuxQRkXmj0Ae6h8Y50n5ZXTsikvMU+sDrpzWrpojkB4U+8atw6yuKuW1FdbpLERGZV3kf\n+tGY88NTYT62sYGCAg3VFJHclvehf/TCZfpGJjX1gojkhbwP/b0tXZjBRzcq9EUk9yn0W8LcuaqG\nunIN1RSR3JfXod87PMFb7f0atSMieSOvQ//102HcNaumiOSPvA7911rC1JYVcceqmnSXIiKyIPI2\n9GMx57VTYT62qYGQhmqKSJ5IKvTNbIeZtZhZq5k9dZ11Pmdmx83smJn9XUL7Y2Z2Ong8lqrC5+rt\ni5fpGZ5Qf76I5JVp75FrZiHgeeABoB3Yb2a7E29wbmYbgaeB+9y9z8yWBO11wBeBJsCBA8G2fanf\nlZl5rSU+9YKGaopIPknmSH8b0Orube4+AewCHp6yzq8Dz18Jc3fvCtofAl51997gvVeBHakpfW72\nngpzx6pq6itK0l2KiMiCSSb0VwLnE5bbg7ZEm4BNZvaGmb1pZjtmsC1m9oSZNZtZczgcTr76Weof\nmeDQuT62a9SOiOSZVJ3ILQQ2AtuBR4GvmlnSQ2Lc/QV3b3L3poaG+Q/ifa3dxBxNvSAieSeZ0L8A\nrE5YXhW0JWoHdrv7pLu/C5wi/iOQzLYL7o3WHipLC7lTQzVFJM8kE/r7gY1mts7MioFHgN1T1vk2\n8aN8zKyeeHdPG/AK8KCZ1ZpZLfBg0JZWJzoGuG1FNYWhvB2xKiJ5atrUc/cI8CTxsD4BvOjux8zs\nOTP7TLDaK0CPmR0HfgD8obv3uHsv8CfEfzj2A88FbWkTizktnYNsXl6ZzjJERNJi2iGbAO6+B9gz\npe2ZhNcO/H7wmLrtTmDn3MpMnXO9I4xORtmyrCrdpYiILLi869842TkAoCN9EclLeRf6JzoGKTDY\nuEShLyL5J+9C/2TnAGvry1lUHEp3KSIiCy4PQ39Q/fkikrfyKvSHxyOc7Rlh8zJ17YhIfsqr0G+5\nNAjA5uU60heR/JRXoX+yIwh9HemLSJ7Kr9DvHKCipJBVtYvSXYqISFrkV+h3DLJ5WSVmulOWiOSn\nvAl9d+dE54AuyhKRvJY3oX/x8hiDYxE2a7imiOSxvAn9kx3x6Re26EhfRPJY/oR+Z3zkzqalCn0R\nyV95E/onOgZYXbeIytKidJciIpI2eRP6JzsH1Z8vInkvL0J/bDJKW3iILbooS0TyXF6EfmvXEDHX\n9AsiInkR+ieCkTuafkFE8l1SoW9mO8ysxcxazeypa7z/uJmFzexw8Pi1hPeiCe1Tb6i+IE52DlJa\nVMCaxeXp+ONFRDLGtPfINbMQ8DzwANAO7Dez3e5+fMqq33D3J6/xEaPuftfcS529k50D3Ly0klCB\npl8QkfyWzJH+NqDV3dvcfQLYBTw8v2WljrtzokMjd0REILnQXwmcT1huD9qm+iUzO2Jm3zSz1Qnt\npWbWbGZvmtln51LsbISHxukdntCcOyIipO5E7kvAWne/A3gV+HrCe2vcvQn4FeAvzGzD1I3N7Ing\nh6E5HA6nqKS49+bQ15G+iEgyoX8BSDxyXxW0XeXuPe4+Hiz+NXBPwnsXguc2YC+wdeof4O4vuHuT\nuzc1NDTMaAemc7JTI3dERK5IJvT3AxvNbJ2ZFQOPAO8bhWNmyxMWPwOcCNprzawkeF0P3AdMPQE8\nr052DLKsqpTa8uKF/GNFRDLStKN33D1iZk8CrwAhYKe7HzOz54Bmd98N/LaZfQaIAL3A48HmW4C/\nMrMY8R+YL19j1M+8OtE5qP58EZHAtKEP4O57gD1T2p5JeP008PQ1tvsRcPsca5y1yWiM1q5BPr4p\ntV1GIiLZKqevyG0LDzMZdc2hLyISyOnQf+8krkbuiIhAjof+iY5BikLG+gZNvyAiAjke+ic7B7hp\nSSVFoZzeTRGRpOV0Gp7sGNQc+iIiCXI29PuGJ+gcGONmhb6IyFU5G/pXboSuG6eIiLwnh0M/PnJH\n3TsiIu/J3dDvGKSuvJiGypJ0lyIikjFyN/Q7B9i8rBIz3ThFROSKnAz9aMxpuaQbp4iITJWToX+2\nZ5ixyZgmWhMRmSInQ//KyJ0tOtIXEXmf3Az9jgEKDDYurUh3KSIiGSUnQ/9E5yDr6sspLQqluxQR\nkYySk6F/snNAF2WJiFxDzoX+0HiE872juihLROQaci70W65Mv6CTuCIiH5BU6JvZDjNrMbNWM3vq\nGu8/bmZhMzscPH4t4b3HzOx08HgslcVfy9Ubp2i4pojIB0x7j1wzCwHPAw8A7cB+M9t9jRucf8Pd\nn5yybR3wRaAJcOBAsG1fSqq/hpMdg1SWFLKyZtF8/REiIlkrmSP9bUCru7e5+wSwC3g4yc9/CHjV\n3XuDoH8V2DG7UpMTP4mr6RdERK4lmdBfCZxPWG4P2qb6JTM7YmbfNLPVM9w2Jdydkx2afkFE5HpS\ndSL3JWCtu99B/Gj+6zPZ2MyeMLNmM2sOh8OzLuJC/yiD4xH154uIXEcyoX8BWJ2wvCpou8rde9x9\nPFj8a+CeZLcNtn/B3ZvcvamhoSHZ2j/gZIdG7oiI3Egyob8f2Ghm68ysGHgE2J24gpktT1j8DHAi\neP0K8KCZ1ZpZLfBg0DYvrozc0S0SRUSubdrRO+4eMbMniYd1CNjp7sfM7Dmg2d13A79tZp8BIkAv\n8Hiwba+Z/QnxHw6A59y9dx72A4hPv9BYV0ZFybS7JSKSl5JKR3ffA+yZ0vZMwuungaevs+1OYOcc\nakzayY74jVNEROTacuaK3LHJKO92D2vOHRGRG8iZ0B8aj/Dzd6xg29q6dJciIpKxcqbzu76ihP/2\n6NZ0lyEiktFy5khfRESmp9AXEckjCn0RkTyi0BcRySMKfRGRPKLQFxHJIwp9EZE8otAXEckj5u7p\nruF9zCwMnJ3DR9QD3SkqJxPk2v5A7u1Tru0P5N4+5dr+wAf3aY27Tzs3fcaF/lyZWbO7N6W7jlTJ\ntf2B3NunXNsfyL19yrX9gdnvk7p3RETyiEJfRCSP5GLov5DuAlIs1/YHcm+fcm1/IPf2Kdf2B2a5\nTznXpy8iIteXi0f6IiJyHTkT+ma2w8xazKzVzJ5Kdz2pYGZnzOyomR02s+Z01zNTZrbTzLrM7O2E\ntjoze9XMTgfPtemscaaus0/LHDdmAAADI0lEQVTPmtmF4Hs6bGafSmeNM2Fmq83sB2Z23MyOmdnv\nBO1Z+T3dYH+y+TsqNbOfmtlbwT79x6B9nZn9JMi8b5hZcVKflwvdO2YWAk4BDwDtxG/E/qi7H09r\nYXNkZmeAJnfPyvHFZvYxYAj4n+5+W9D2X4Bed/9y8ONc6+5/nM46Z+I6+/QsMOTuf5rO2mbDzJYD\ny939oJlVAgeAzwKPk4Xf0w3253Nk73dkQLm7D5lZEbAP+B3g94F/dPddZvaXwFvu/pXpPi9XjvS3\nAa3u3ubuE8Au4OE015T33P2HQO+U5oeBrwevv078H2TWuM4+ZS1373D3g8HrQeAEsJIs/Z5usD9Z\ny+OGgsWi4OHAzwLfDNqT/o5yJfRXAucTltvJ8i864MD3zOyAmT2R7mJSZKm7dwSvO4Gl6SwmhZ40\nsyNB909WdIVMZWZrga3AT8iB72nK/kAWf0dmFjKzw0AX8CrwDtDv7pFglaQzL1dCP1fd7+53A/8M\n+K2gayFneLxvMfv7F+ErwAbgLqAD+LP0ljNzZlYBfAv4XXcfSHwvG7+na+xPVn9H7h5197uAVcR7\nNjbP9rNyJfQvAKsTllcFbVnN3S8Ez13A/yb+ZWe7S0G/65X+16401zNn7n4p+EcZA75Kln1PQT/x\nt4D/5e7/GDRn7fd0rf3J9u/oCnfvB34AfBioMbPC4K2kMy9XQn8/sDE4m10MPALsTnNNc2Jm5cGJ\nKMysHHgQePvGW2WF3cBjwevHgO+ksZaUuBKOgV8ki76n4CTh/wBOuPt/TXgrK7+n6+1Pln9HDWZW\nE7xeRHzAygni4f/LwWpJf0c5MXoHIBiC9RdACNjp7l9Kc0lzYmbriR/dAxQCf5dt+2Rmfw9sJz4b\n4CXgi8C3gReBRuKzqX7O3bPmxOh19mk78W4DB84Av5HQH57RzOx+4HXgKBALmv898X7wrPuebrA/\nj5K939EdxE/UhogfqL/o7s8FGbELqAMOAb/q7uPTfl6uhL6IiEwvV7p3REQkCQp9EZE8otAXEckj\nCn0RkTyi0BcRySMKfRGRPKLQFxHJIwp9EZE88v8BiZYNFSylVVsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vbu5RZrUAkg8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "483b3d7d-5ca0-4aa9-9115-09ed862fe202"
      },
      "source": [
        "X_train[0]"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
              "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
              "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
              "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
              "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
              "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
              "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
              "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
              "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
              "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
              "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
              "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
              "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7hqoYQMAqP_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e5f8bc72-fb9d-4330-b6cd-e8e032e9093c"
      },
      "source": [
        "y_train[0]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    }
  ]
}